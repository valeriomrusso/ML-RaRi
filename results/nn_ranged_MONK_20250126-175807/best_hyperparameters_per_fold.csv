lambda,batch_size,units,dropout,num_layers,units_hidden,learning_rate,momentum,fold,train_loss,val_loss,accuracy,val_accuracy,mse,val_mse
1.1842035811512663e-06,96,256,0.4,9,192,0.002184633092200579,0.5,1,0.4747474789619446,0.6000000238418579,0.25257059931755066,0.2501430809497833,0.25047385692596436,0.24804633855819702
3.149458263748931e-06,72,256,0.0,8,160,0.0002119225054468749,0.8,2,0.6363636255264282,0.6399999856948853,0.25300607085227966,0.25315821170806885,0.2488253265619278,0.24897746741771698
0.13971489121718095,64,512,0.4,5,224,0.005692108784937963,0.9,3,0.5252525210380554,0.4000000059604645,0.3631705343723297,0.36745792627334595,0.24942852556705475,0.2537159323692322
1.8655451151122812e-06,124,32,0.2,6,128,0.00033123013429151,0.0,4,0.6767676472663879,0.6399999856948853,0.24888481199741364,0.24998848140239716,0.24758198857307434,0.24868562817573547
6.620346838213957e-05,120,32,0.4,1,256,0.0011723061988515647,0.1,5,0.6200000047683716,0.7083333134651184,0.24175935983657837,0.23298196494579315,0.23719672858715057,0.22841931879520416

lambda,batch_size,units,dropout,num_layers,units_hidden,learning_rate,fold,mse,val_mse
6.0510488874799316e-06,88,128,0.0,1,128,0.0025836130092226042,1,0.02707527205348015,0.0633544996380806
6.298882407177218e-06,76,64,0.1,2,96,0.0004766522588100132,2,0.03013775683939457,0.09767912328243256
3.1995578290681883e-06,20,32,0.1,1,128,0.002260546283544172,3,0.029038896784186363,0.07193116098642349
1.6045521296543702e-05,72,128,0.2,2,128,0.003412646114724423,4,0.05797993019223213,0.02838578261435032
1.5954125711854483e-05,128,128,0.1,1,128,0.00952696747033435,5,0.03410359472036362,0.016937043517827988
